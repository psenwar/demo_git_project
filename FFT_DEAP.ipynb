{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FFT- DEAP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTr_ycAQfFgO"
      },
      "source": [
        "# Importing required Librabries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZgJPO-bvo4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1dfb58-6fdc-4383-c421-8bce76f5f125"
      },
      "source": [
        "!pip install git+https://github.com/forrestbao/pyeeg.git\n",
        "import numpy as np\n",
        "import pyeeg as pe\n",
        "import pickle as pickle\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/forrestbao/pyeeg.git\n",
            "  Cloning https://github.com/forrestbao/pyeeg.git to /tmp/pip-req-build-rosnpwq4\n",
            "  Running command git clone -q https://github.com/forrestbao/pyeeg.git /tmp/pip-req-build-rosnpwq4\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyeeg==0.4.4) (1.19.5)\n",
            "Building wheels for collected packages: pyeeg\n",
            "  Building wheel for pyeeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyeeg: filename=pyeeg-0.4.4-py2.py3-none-any.whl size=28123 sha256=66839c2dee4fb00136b6199cd9906441b7a663e65400a290c5d1cff460be9344\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-clru_824/wheels/2d/3f/ad/106d4fc80b61d1ea1fc18e76e7439fd98aa043d83d58eae741\n",
            "Successfully built pyeeg\n",
            "Installing collected packages: pyeeg\n",
            "Successfully installed pyeeg-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6V-0VlCv8F3"
      },
      "source": [
        "import pandas as pd\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWlMgzPBwGwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6771ebec-8874-4302-9c45-6e992571e069"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOXuEM0JwJqI"
      },
      "source": [
        "os.getcwd()\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/data_preprocessed_python')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCMT74t9wowG"
      },
      "source": [
        "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31]\n",
        "band = [4,8,12,16,25,45] #5 bands\n",
        "length_window = 256 # 2 sec\n",
        "size_step = 16 #Each 0.125 sec \n",
        "frequency_sample = 128 #   128 hz\n",
        "Total_subjects = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCimkyHQejAU"
      },
      "source": [
        "# Fast Fourier Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmU8hadR49MM"
      },
      "source": [
        "def Fast_Fourier_Transform (subject, channel, band, length_window, step_size, frequency_sample,c):\n",
        "\n",
        "    processed = []\n",
        "    data_frame=open(subject,'rb')\n",
        "\n",
        "    subject_data = pickle.load(data_frame,encoding = \"latin1\")  \n",
        "\n",
        "    for i in range (0,39):\n",
        "        data = subject_data[\"data\"][i]\n",
        "        labels = subject_data[\"labels\"][i]\n",
        "        start = 0;\n",
        "\n",
        "        while start + length_window < data.shape[1]:\n",
        "            processed_array = []\n",
        "            processed_data = [] #meta vector for analysis\n",
        "            for j in channel:\n",
        "                X = data[j][start : start + length_window]     #Slice raw data over 2 sec, at interval of 0.125 sec\n",
        "                Y = pe.bin_power(X, band, frequency_sample)       #FFT over 2 sec of channel j, in sequence of theta, alpha, low beta, high beta, gamma\n",
        "                processed_data = processed_data + list(Y[0])\n",
        "\n",
        "            processed_array.append(np.array(processed_data))\n",
        "            processed_array.append(labels)\n",
        "\n",
        "            processed.append(np.array(processed_array))    \n",
        "            start = start + size_step\n",
        "            \n",
        "    processed = np.array(processed)\n",
        "    np.save('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/s' + str(c), processed, allow_pickle=True, fix_imports=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWcHt5X2xDfw"
      },
      "source": [
        "import glob\n",
        "FilesTotal = glob.glob(\"/content/drive/MyDrive/Colab Notebooks/data_preprocessed_python\" + \"/*.dat\")\n",
        "c=1\n",
        "for subject in FilesTotal:\n",
        "    Fast_Fourier_Transform (subject, channel, band, length_window, size_step, frequency_sample,c)\n",
        "    c = c +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM2Bdu7oxIbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f73fce-9ffc-49c4-9ab2-c9e617ad088c"
      },
      "source": [
        "X_training = []\n",
        "Y_training = []\n",
        "X_testing = []\n",
        "Y_testing = []\n",
        "\n",
        "for subjects in Total_subjects:\n",
        "\n",
        "    with open('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/s' + subjects + '.npy', 'rb') as file:\n",
        "      sub_data = np.load(file,allow_pickle=True)\n",
        "      for i in range (0,sub_data.shape[0]):\n",
        "        if i % 5 == 0:\n",
        "          X_testing.append(sub_data[i][0])\n",
        "          Y_testing.append(sub_data[i][1])\n",
        "        else:\n",
        "          X_training.append(sub_data[i][0])\n",
        "          Y_training.append(sub_data[i][1])\n",
        "\n",
        "np.save('//content/drive/MyDrive/Colab Notebooks/DEAP  - saved/data_training', np.array(X_training), allow_pickle=True, fix_imports=True)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/label_training', np.array(Y_training), allow_pickle=True, fix_imports=True)\n",
        "print(\"training dataset:\", np.array(X_training).shape, np.array(Y_training).shape)\n",
        "\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/data_testing', np.array(X_testing), allow_pickle=True, fix_imports=True)\n",
        "np.save('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/label_testing', np.array(Y_testing), allow_pickle=True, fix_imports=True)\n",
        "print(\"testing dataset:\", np.array(X_testing).shape, np.array(Y_testing).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training dataset: (473539, 70) (473539, 4)\n",
            "testing dataset: (118405, 70) (118405, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}