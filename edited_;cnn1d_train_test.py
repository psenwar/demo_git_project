# -*- coding: utf-8 -*-
"""EDITED**;CNN1D_TRAIN_TEST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tqa-l8dIX7m7YaDHwHYwYEM-6WV3uGc6
"""

!pip install git+https://github.com/forrestbao/pyeeg.git

import pandas as pd
import keras.backend as K
import numpy as np
import pandas as pd
import pyeeg as pe
import pickle as pickle
import math

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers.convolutional import Convolution1D, MaxPooling1D, ZeroPadding1D,Conv1D
from keras.models import Sequential
from keras.utils import to_categorical 

from keras.models import Model
import timeit
from keras.optimizers import SGD


import warnings
warnings.filterwarnings('ignore')


from sklearn import svm
from sklearn.preprocessing import normalize

import os
import time

from google.colab import drive
drive.mount('/content/drive/')

"""# Getting data """

with open('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/data_training.npy', 'rb') as fileX_training:
    X_train  = np.load(fileX_training)
    
with open('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/label_training.npy', 'rb') as fileY_training:
    Y_train  = np.load(fileY_training)
    
X_train = normalize(X_train)
Z_train = np.ravel(Y_train[:, [3]])
#labels
train_arousal = np.ravel(Y_train[:, [0]])
train_valence = np.ravel(Y_train[:, [1]])
train_dominance = np.ravel(Y_train[:, [2]])
train_liking = np.ravel(Y_train[:, [3]])

X_train.shape
from keras.utils import to_categorical
y_train = to_categorical(Z_train)
y_train
y_train.shape
x_train = np.array(X_train[:])

with open('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/data_testing.npy', 'rb') as fileX_training:
    X_test  = np.load(fileX_training)
    
with open('/content/drive/MyDrive/Colab Notebooks/DEAP  - saved/label_testing.npy', 'rb') as fileY_training:
    Y_test  = np.load(fileY_training)

X_test = normalize(X_test)
Z_test = np.ravel(Y_test[:, [3]])

test_arousal = np.ravel(Y_test[:, [0]])
test_valence = np.ravel(Y_test[:, [1]])
test_dominance = np.ravel(Y_test[:, [2]])
test_liking = np.ravel(Y_test[:, [3]])

x_test = np.array(X_test[:])

from keras.utils import to_categorical
y_test = to_categorical(Z_test)
y_test

y_test[1]

from sklearn.preprocessing import StandardScaler
temp = StandardScaler()
x_train = temp.fit_transform(x_train)
x_test = temp.fit_transform(x_test)

"""# CNN1D Model"""

x_train = x_train.reshape(x_train.shape[0],x_train.shape[1], 1)
x_test = x_test.reshape(x_test.shape[0],x_test.shape[1], 1)
x_train.shape
batch_size = 256
classes = 10

input_shape=(x_train.shape[1], 1)
print(input_shape)

from keras.layers import Convolution1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense
from keras.regularizers import l2

model_CNN1d = Sequential()
intput_shape=(x_train.shape[1], 1)
model_CNN1d.add(Conv1D(128, kernel_size=3,padding = 'same',activation='relu', input_shape=input_shape))
model_CNN1d.add(BatchNormalization())
model_CNN1d.add(MaxPooling1D(pool_size=(2)))
model_CNN1d.add(Conv1D(128,kernel_size=3,padding = 'same', activation='relu'))
model_CNN1d.add(BatchNormalization())
model_CNN1d.add(MaxPooling1D(pool_size=(2)))
model_CNN1d.add(Conv1D(64,kernel_size=3,padding = 'same', activation='relu'))
model_CNN1d.add(MaxPooling1D(pool_size=(2)))
model_CNN1d.add(Flatten())
model_CNN1d.add(Dense(64, activation='tanh'))
model_CNN1d.add(Dropout(0.2))
model_CNN1d.add(Dense(32, activation='tanh'))
model_CNN1d.add(Dropout(0.2))
model_CNN1d.add(Dense(16, activation='relu'))
model_CNN1d.add(Dropout(0.2))
model_CNN1d.add(Dense(classes, activation='softmax'))
model_CNN1d.summary()

model_CNN1d.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])

"""# Training and Testing Model"""

iter = 5

grpah_model=model_CNN1d.fit(x_train, y_train,batch_size=batch_size,epochs=iter,  verbose=1,validation_data=(x_test,y_test))

model_score = model_CNN1d.evaluate(x_test, y_test, verbose=1)
print('Test loss:', model_score[0])
print('Test accuracy:', model_score[1])

"""# Plots"""

# list all data in history
print(grpah_model.history.keys())
import matplotlib.pyplot as plt
import numpy

"""### Epochs vs Accuracy"""

# summarize history for accuracy
plt.plot(grpah_model.history['accuracy'])
plt.plot(grpah_model.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### Epochs vs Loss"""

# summarize history for loss
plt.plot(grpah_model.history['loss'])
plt.plot(grpah_model.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(grpah_model.history['val_accuracy'])
plt.plot(grpah_model.history['val_loss'])
plt.title('test model')
plt.ylabel('test accuracy')
plt.xlabel('test loss')
plt.show()

"""### Confusion Matrix showing all classes"""

y_pred=model_CNN1d.predict(x_test)
from sklearn.metrics import confusion_matrix
import numpy as np

y_test[1]
y_pred[1]
y_test1=np.argmax(y_test, axis=1)
y_pred=np.argmax(y_pred,axis=1)
cmatrix=confusion_matrix(y_test1, y_pred)
import seaborn as sns
figure = plt.figure(figsize=(8, 8))
sns.heatmap(cmatrix, annot=True,cmap=plt.cm.Blues)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

"""# ROC Curve"""

import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp
from sklearn.metrics import roc_auc_score

# make probability predictions with the model
predictions = model_CNN1d.predict(x_test)
# round predictions 
rounded = [round(x[0]) for x in predictions]
rounded = np.array(rounded)
rounded.shape

# make class predictions with the model
predictions = model_CNN1d.predict_classes(x_test)

temp = label_binarize(predictions,classes = [0,1,2,3,4,5,6,7,8,9] )
temp
temp1 = label_binarize(y_test,classes = [0,1,2,3,4,5,6,7,8,9] )
temp1

n_classes = classes


# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes-1):
    fpr[i], tpr[i], _ = roc_curve(temp1[:, i], temp[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(temp1.ravel(), temp.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

n_classes = n_classes  -1
lw = 2

all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))

# Then interpolate all ROC curves at this points
mean_tpr = np.zeros_like(all_fpr)
for i in range(n_classes):
    mean_tpr += interp(all_fpr, fpr[i], tpr[i])

# Finally average it and compute AUC
mean_tpr /= (n_classes)

fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])

# Plot all ROC curves
plt.figure()
plt.plot(fpr["micro"], tpr["micro"],
         label='micro-average(area = {0:0.2f})'
               ''.format(roc_auc["micro"]),
         color='deeppink', linestyle=':', linewidth=4)

plt.plot(fpr["macro"], tpr["macro"],
         label='macro-average(area = {0:0.2f})'
               ''.format(roc_auc["macro"]),
         color='navy', linestyle=':', linewidth=4)

colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=lw,
             label='class {0} (area = {1:0.2f})'
             ''.format(i, roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=lw)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('multi-class ROC')
plt.legend(loc="lower right")
plt.show()

cm = cmatrix
cm

recall = np.diag(cm) / np.sum(cm, axis = 1)
precision = np.diag(cm) / np.sum(cm, axis = 0)

print("Recall",np.nanmean(recall))
print("{Recall}",np.nanmean(precision))